%!TEX root=main.tex
\section{Philosophical Lessons: On the Boundaries of the Model Concept}	% (fold) 
\label{sec:analysis}


In this final section, we develop four lessons from the foregoing discussion and investigate their consequences for the present philosophical debates on models. First, we find that the SM-EFT cannot be categorized as simply as explicit BSM models or simplified models. We will do so by looking at the MaM approach (\ref{sub:autonomy}) and Hartmann's version of a semantic (\ref{sub:modelhood}) approaches. Second, even though the three stages presented in the previous section must be considered as parts of a coherent epistemic strategy, the autonomy and representational features are different for the stages, affecting their respective modelhood (\ref{sub:smeftrep}).
Third, we argue that the fact that one applies the same theoretical and experimental techniques in the SM-EFT approach as are used in the study of BSM models and simplified models, does not automatically render the SM-EFT a model (\ref{sub:epistemic}). 
This shows, to our mind, why, more generally, it might be attractive to investigate the boundary of the model concept rather than advocate a liberal use. 
Fourth, we argue that focusing on models and their representative features can provide an ontologically lean perspective on EFTs insofar as it does not require to take a general stance on realism, in contrast to large part of the present debates.


\subsection{Is SM-EFT an Autonomous Mediator?} % (fold)
\label{sub:autonomy}

As noted in Section~\ref{sec:models} above, it is rather uncontroversial that models are constructed to fulfil specific purposes and that they help us learn about a theory or a target system, respectively.
These basic elements of the MaM approach not only apply to BSM models and simplified models, but also to SM-EFT, whose purpose is efficiently accounting for possible deviations in order to possibly place constraints on models of BSM physics. 
The partial autonomy from data and theory, another element of MaM, makes for a more interesting analysis.\footnote{We will discuss the fourth element, representation, in Sec.~\ref{sub:smeftrep}.}
Let us start with the autonomy of explicit BSM models.
In [reference omitted] it was argued that BSM models stand in a twofold mediating relationship because they are placed within the framework of quantum field theory or a more general successor theory and they must simultaneously recover the SM as a low-energy limit. 
Or put otherwise, they must recover the SM as a top-down EFT.
From this we see that SM-EFT is at least partly autonomous from data. While it features all the SM fields whose properties must accord with data, the many additional terms are only determined by general theoretical considerations, such as the SM symmetries.

\citet{mccoymassimi} have argued that simplified models are autonomous from data and `theory' (here meaning full BSM models, like supersymmetry) because a simplified model is partly independent from any particular BSM model. 
Due to their autonomy, they argue, simplified models can play a role mediating between data and BSM models analogously to the mediating role played by models in the original MaM account. 
Yet, this autonomy must be qualified because the particle content of a simplified model is borrowed from a potentially large class of BSM models. 
For example, a simplified model may feature a new scalar top-like particle, but such a particle has originally been proposed within a class of full BSM models. 
The main point is that simplified models do not specify all properties of the additional fields, admitting a large space of physical possibilities.
McCoy \& Massimi call such modelling perspectival because it does not require representation in the sense of a mapping onto a target or ``onto an actual worldly-state-of-affairs (or suitable parts thereof) but representation has instead a modal aspect: it is about exploring and ruling out the space of possibilities in domains that are still very much open-ended for scientific discovery" \citep[p.~338]{mccoymassimi}.
The initial space of possibilities in the SM-EFT is much larger than the one of simplified models because, at least initially, it is no longer motivated by any properties of classes of models, outside of the SM. 
Thus, the perspectival modelling cannot be further extended to consider SM-EFT a model.
At Stage 1, there is no clear and distinct perspective to take. 

SM-EFT is not autonomous from theory in that it uses a theoretically well-established procedure in expanding the Lagrangian into operators of higher dimensions. 
Only fields of the SM theory are used and the basic symmetries of the SM are retained. 
Hence the SM-EFT is, at Stage 1, determined by general theoretical principles and a well-confirmed theory, the SM, but not by any particular BSM models; all formally possible terms are taken into consideration.  
Here, one operates in a generic space of possibilities that parametrizes our ignorance and can be used for exploratory experimental searches. 
According to \cite{wells2011}, this generic approach is even a requirement of mathematical consistency, to avoid divergences and maintain the independence of arbitrary scale cut-offs. 
Leaving out terms destroys the renormalizability of the theory, and if one picks out certain terms the corrections might be associated with terms that had been left out. 
Thus at the first stage, SM-EFT has little autonomy from the SM and the framework theory. 
In Stage 2, any such autonomy is only apparent because it arises as the product of pragmatic decisions for the sake of tractability or simplicity.
But even if the mathematical consistency is lost, a Stage 2 EFT for special sectors is largely determined by the SM in its field contents and symmetries. This also shows that particle physicists care much less than philosophers about renormalization or interpretability at steps or stages of an investigation into new physics.


A Stage-3 EFT is, however, sufficiently autonomous from theory that it could be considered a model. 
Crowther \citep{Crowther2016-CROESU} argues for the autonomy (or quasi-autonomy) of EFTs, what we consider Stage-3.
She says that ``the idea of autonomy (or, rather, quasi-autonomy) in EFT comes from the fact that the low-energy theory is largely independent of the details of the high-energy theory. There is extra information contained in the high-energy theory, far over-and-above that required in order to describe the low-energy behaviour of significance.'' 
This autonomy makes the EFT robust against changes in the microphysics and together with the fact that is a novel description, implies for her that EFTs are emergent.  
A Stage-3 EFT can simply be written down to model some new interaction, in which case, its autonomy from the full theory (as well as a clear target of representation, and hence modelhood) is introduced by hand. 
However, one may also arrive at a Stage-3 EFT based on the systematic expansion in SM-EFT, where the relevant EFT operators are selected by deviations from the SM observed in measurements. 
In this sense, SM-EFT is an example of a potentially successful bottom-up strategy that accomplishes autonomy from the theoretical description in terms of products of SM-operators. 
In such a case, the SM-EFT approach would become the proverbial Wittgensteinian ladder; a formal theory to be thrown away and replaced by a concrete BSM model introducing a new field, a simplified model, or a vertex model of some new phenomenon in the same style as the Fermi theory had done for beta-decay.


\subsection{SM-EFT in Hierarchical Approaches}
\label{sub:modelhood}

Let us now return to the problem handed to us by \citet{hartmann2001}, namely the difficulty in disentangling EFTs from models and theories and address it in the context of Hartmann's (\citeyear{hartmann95}) hierarchical approach discussed in Section~\ref{sub:modeltheory}. 
Theory has here to be understood in the double sense of a Type-A theory (such as QFT) and a Type-B theory (such as the SM). 
All explicit BSM models can be subsumed under Hartmann's classification, although it is sometimes a matter of how `fundamental' their aspirations are and whether there are presently any real or purported phenomena they describe.\footnote{MS: Recall that Hartmann's notion of fundamental is defined with respect to the present experimental knowledge and does not involve any reductionist aspirations.}
Supersymmetry (SUSY) e.g. may be considered a Type-B theory %as being a concretization of QFT, which 
that captures all that can be said in its intended domain of applicability; it is true, key features of SUSY have not been empirically validated. 
However, it can also be interpreted as a Type-A model if one interprets SUSY just as one way to provide inputs for a more fundamental theory. 
This can be motivated by the different symmetry breaking mechanisms invoked in special realizations of SUSY. 
Other concrete BSM models, like technicolor and Randall-Sundrum models, do not have the rather fully worked out fundamental structure, such that they would be considered as capturing their total domain of applicability. 
In this sense, they can be classified as Type-A models in virtue of their serving as `input for more fundamental constructs'. 
However, there may also be an emphasis on the phenomenological aspects of these models in the sense of Type-B models introducing a `structure that cannot be deduced from that theory'. 
Such a characterization is certainly appropriate if models (partly) work outside the framework of QFT; variants of extra-dimensional modes can be counted as such. 
Given that simplified models are developed from BSM models, they should be classified as Type-A or Type-B models depending on how their space of possibilities is configured.
Recall that, as mentioned in Section~\ref{sub:modeltheory}, Hartmann's requirements for a Type-B model are lower than in the MaM approach; thus it seems to us plausible that the reasoning of McCoy and Massimi concerning representation can be carried over into a modification of Hartmann's approach.

Since for Hartmann the Fermi theory is an EFT and a phenomenological model, one may wonder whether SM-EFT overall can be considered as a model in a non-trivial sense, that is, beyond the fact that any SM-EFT is formulated in terms of a Lagrangian and thus a formal model of QFT.
As argued in Section~\ref{sub:autonomy}, SM-EFT is, at Stage 1, primarily influenced by theoretical considerations, such as symmetries and renormalization. 
It is a formal technique allowed within the context of a Type-A framework theory and strongly dependent on the existence of a well-established and well-tested model, or a Type B theory, such that the formal operators of higher order can be experimentally analysed as deviations from the SM. 

But in contrast to concrete BSM models or simplified models, SM-EFT at Stage 1 is neither a toy model \citep[see][]{Reutlinger2018} that could provide understanding of a Type-A or Type-B theory, nor a variant of a Type-A or Type-B theory. 
By integrating all formal possibilities, SM-EFT is also too unspecific to provide meaningful input for fundamental constructs. 
It merely provides a theoretical space for experimental exploration.
Similar arguments apply for Stage 2, at least in general and unless going to Stage 2 was motivated by certain assumptions about candidate models.
Merely truncating the Lagrangian expansion in Eq.~\ref{eq:smeft} or focusing on the top quark or the Higgs sector does not provide a sufficiently well-defined target for BSM searches.
It is only at Stage~3, once significant deviations from the SM have been found, or are assumed to be present, that the SM-EFT can be seen as
a phenomenological model of Type-B, i.e., as about some object or system.
One may then understand SM-EFT in the same way as the early Fermi theory, i.e., as a description of some physical process that is based on vertices instead of force-mediating fields, and that could be described within some Type-A theory.
We thus find that SM-EFT, given its close relation to Type-A and B theories, in principle falls within Hartmann's hierarchical conception, but that it is not possible to interpret the first two stages as models even though they are formally expressed as theories.
The whole point of SM-EFT is to use the formal machinery of a well-confirmed theory to search for deviations, that is, to explore its limits in order to search for new physics. 
If the SM-EFT strategy would eventually yield hints on a BSM model, this would not count as an unintended model of the framework theory either.
To move forward from this mixed outcome, it is helpful to recall Hartmann's distinction between the global perspective of a theory and the local understanding provided by models \citep{hartmann2001}. 
Some theories, such as SM-EFT, may fail to provide local understanding, even though typically theories unify the local understanding of the models that fall under them.


\subsection{Does SM-EFT Represent Anything?}
\label{sub:smeftrep} 

We outlined in Sect.~\ref{sec:physrepres} the importance of representation for physicists searching for BSM effects. 
While we thus think that accurate representation plays a significant role in the practice of particle physics, we have seen in Section ~\ref{sub:reptarget} that scholars disagree on its philosophical importance in characterising modelhood. 
While it figures among the four basic elements of the MaM approach, and in McCoy \& Massimi's application of MaM to simplified models, other practice-based approaches, among them Knuuttila's, treat representation as an asset in successful modelling practice but not as an essential precondition of being a model. 
We will discuss these two approaches in the next two sections in order to investigate whether SM-EFT represents at all stages, within the context of these approaches, and to what extent the outcome of this analysis matches the research practice in present-day elementary particle physics.\footnote{Hartmann's papers discuss the representation within the context of idealization. Models represent some object system in an idealized fashion, and there is a variety of idealization strategies on all four levels. Without going into further detail, we believe that his diagnosis about the representation of SM-EFT would largely agree with our conclusion concerning the MaM approach. There is nothing that SM-EFT at stage 1 could be an idealization of.}
The key problem of our analysis will not lie in the specifics of the concept of representation applied, but in whether SM-EFT at all stages has a target that is specific enough to allow us to speak meaningfully about representation.


Representation in bottom-up EFTs is complex and depends on the stage.
Let us start with the Fermi theory that may be considered as a Stage-3 EFT. 
Even without having an idea of the larger SM framework, the original theory represented the phenomenon of beta-decay in terms of the input (down quark) and the output (electron, neutrino, and up quark) by respective wave-functions.~\footnote{In agreement with Eq.~\ref{eq:Fermi} we use modern notation.}
Similarly, one can today write down BSM approaches by using a few EFT operators, as exemplified in Sect.~\ref{sec:BphysicsConcepts}, in which each term is a representation of a field and its properties.
Such representational terms can be motivated by factual indications, by having a BSM physics idea like preons, leading to almost an identical equation, or just by a parametrization of a possible deviation from the SM without a definite physics idea like $e^+e^-\rightarrow W^+W^-$.
Thus, Stage 3 is representative and a clear target for experimental and theoretical evaluations is identified.
This is also the case if such a target appears without any previous phenomenon or physics idea as a result of experimental investigations of deviations from the SM conducted within the context of the SM-EFT strategy that result in one or two terms of the initial expansion having non-zero coefficients.

At Stage 2, some broader area of interest is specified, e.g. the Higgs sector, which, 
out of pragmatic and epistemic reasons, physicists deem the most likely sector to reveal deviations from the SM.
However, there is no specific target defined and there is no representation of a BSM effect.
The space of required observations is significant and the Higgs-EFT is just a parametrization of all possible deviations one may think of, taking into account the theoretical constraints discussed in Section.~\ref{sec:eftintro}. 

This lack of a clear target and its representation is compounded in Stage~ 1. Any target of representation, if there were to be one, would be too vague to be meaningful. 
If we treated the SM-EFT or some part of it as a formal model---after all it is still a Lagrangian---it would not be clear what it would be a model of.
It is an explicit aim of the approach to remain silent on the nature of any new physics because its objective is to be sensitive for experimental deviations from the SM of whatever nature. 
Thus, it is inherent to the bottom-up approach that there is no specific target of representation in Stages 1 and 2.

To us, this indicates that SM-EFT does not exhibit all four elements identified in the MaM approach. 
The characteristics are, however, exhibited in a Stage-3 EFT, when a target of representation is specifiable, even if there is no new field posited.  
But it is clear that if there were evidence of a deviation this is precisely the next step that the physicists would take, either by devising an explicit model or a simplified model (see Section~\ref{sec:physrepres}). 
For this reason, SM-EFT as an epistemic strategy is somewhat orthogonal to the objectives of the MaM approach that starts from a given phenomenon that cannot be effectively explained by theory, if there is any, without the mediation of autonomous models. In the case of SM-EFT, the theory provides only the formal means for a rather open-ended experimental investigation. 
This might be seen in analogy to Morrison's example of the mathematical pendulum discussed in Section~\ref{sub:reptarget} that provides the theoretical means to introduce additional effects, but in contrast to this well-understood de-idealisation, particle physicists have few empirical indications of what the new physics could be like.

BSM models, which virtually all hypothesize new fields and interactions, provide a target with fairly well defined properties. 
These new fields are considered a representation of a possible real phenomenon.
Similarly, simplified models select a few entities to represent an observable phenomenon, even though it may have different physical interpretations if eventually expressed within the context of an explicit BSM model.
Simplified Models put representation centre-stage, as was emphasized by McCoy and Massimi, because one has to properly define what representation means for entities that are only partially specified. 
\citep{massimi2018} has argued more generally that such perspectival modelling avoids contradictions insofar as the same target may well be represented by incompatible models. 
She identifies four aspects of perspectival modelling: i) there is a \textit{plurality} of such models; ii) each model is only a \textit{partial} description; iii) the models are \textit{complementary}; and iv) as we noted above, they are \textit{modal} models in that they represent merely possible rather than actual states of affairs. 
A similar view cannot be applied to SM-EFT which, at Stage 1, does not represent even possible states of affairs, but merely parametrises physicists' ignorance. 
At this stage, there is no group of partial, complementary models along which one can take various incomplete perspectives on a space of possibilities. 

\subsection{The limits of a purely epistemic approach} \label{sub:epistemic}

There are also approaches that most likely would consider SM-EFT as a model at all stages. 
This is rather obvious for a syntactic account because SM-EFT is a formal model of quantum field theory. 
Considering SM-EFT as a theoretical tool for experimental searches for BSM physics renders it as an epistemic tool in the sense of Knuuttila's (\citeyear{knuuttila2011,Knuuttila2017}) artefactual account discussed in Section~\ref{sub:reptarget}.  
There can be little doubt that SM-EFT allows us to learn from data in specific ways and to obtain constraints on possible physics.
It allows one to make inferences at all stages and has a specific design that allows it to be manipulated as an artefact rather than as an abstract object that accurately represents a target.\footnote{See the characteristics mentioned in Section~\ref{sub:reptarget} above.} 
Its justification is distributed over theoretical principles and experimental strategies---while traditional particle physics models are justified by their resolving a certain problem of the SM or by introducing some idea of new physics.
The widespread use of SM-EFT in the community documented in Section~\ref{sec:data} and the existence of a longer tradition of effective theories \citep{wells2011} indicate that the method is indeed `culturally established'. 
The bottom-up EFTs are based on the same experimental and theoretical techniques as studies of the SM and simplified models and explicit models. 

At each stage, the bottom-up SM-EFT approach is described by a Lagrangian 
obeying the principles also used for the SM and the constraints on the EFT parameters are obtained in the same experiments that test BSM models using the same experimental techniques. 
However, there are differences of strategy: theoretical and experimental studies of bottom-up EFT approaches emphasise deviations, whereas studies of BSM models mostly look for the footprint of a new particle against smooth background.
Thus, for epistemic accounts, there seems to be no principal difference between explicit models and the bottom-up approach that eventually aims to arrive at them. 
Since in epistemic accounts of models, representation is a welcome add-on and its absence does not automatically disqualify something from being a model, the bottom-up EFTs, including Stages 1 and 2, would be classified as models.


Fair enough, but the problem we see in Knuuttila's epistemic account is that it does not reflect a key element of the scientific practice of most particle physicists. 
While Knuuttila considers representations and its tools as all of a piece, the SM-EFT strategy puts an extra value on the goal of representation. 
As outlined in Sect.~\ref{sec:physrepres}, it is important for a model to have a well defined target of representation. 
While, as discussed in Sect.~\ref{sub:smeftrep} such a target exists at Stage 3, it is absent at Stages 1 and 2, as exemplified in Sect.~\ref{sec:BphysicsConcepts}. 
For particle physicists, the Stages 1 and 2 are just (if at all) stepping stones towards a representational model of BSM physics.
If induced by experimental findings, the transition between Stages 2 and 3 would signify a major breakthrough.

\subsection{Lessons for the Philosophy of EFT} \label{sub:EFT}

Our analysis of how three philosophical accounts of models address bottom-up EFT strategies, in particular SM-EFT, puts Hartmann's main question, the relationship between model and theory in assessing EFT, back into the focus and gives it a somewhat surprising twist.
SM-EFT at Stage 1 can fail to be a model, at least on the MaM account, and yet still qualify as a theory, while it may have acquired, at Stage 3, the characteristics of a model.
SM-EFT is a theoretical tool that helps experimental physicists to parametrize their constraints or observations of deviations from the SM. 
Such searches may or may not be guided by any explicit models or aspects of models ([reference omitted]).

A bottom-up EFT is certainly not guided by a model or a theory in the usual sense. But our case study clearly shows that there exists a role for theory in scientific practice without the mediation of models. 
This is somewhat at odds both with the general idea of models as mediators between theory and data, and the hierarchical approach of Hartmann and advocates of the semantic approach. 
To be sure, theory in this case does not predict, unify, or explain. 
It is primarily a tool for the parametrization of experimental results that involve research motives that are not connected to specific models or theories.

It seems to us that this differentiation also bears important lessons for the present debates about EFT. 
As mentioned in Sect.~\ref{PhilEFT}, most philosopher understand bottom-up EFTs either as ways to discover a new fundamental level in the tower of theories  or as a way to study the limits of an already specified EFT and support its realist interpretation through a robustness argument. 
If there are any effects of unknown physics at higher energy, they can be absorbed into the parameters of the EFT on the basis of experiments conducted on the scale of its validity. 
In doing so most interpreters consider the limit of validity, the cut-off, as an element of physical reality. When physicists are applying SM-EFT, realism works the opposite way. 
The SM---or in Stage 2: certain sectors of it---are assumed to be real and its parameters are locked in, which allows physicists to look for deviations from those values of whatever kind and without any commitments about their nature. 
They are looking for constraints on BSM physics or some target of further analysis, for some thing to model. 
It seems to us that philosophically this goal to obtain a target and eventually a model that represents new physics is more modest in kind than the realist discourse that present discussions about EFT are embedded in and physicists applying SM-EFT may remain agnostic about realism vs. instrumentalism or reduction vs. emergence. 
This extends to their attitude about the cut-off. It has to allow potential new physics to reveal itself, but not enough to dominate the physics at the low energy level.
