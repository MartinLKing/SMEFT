%!TEX root=main.tex
\section{EFTs: Between Models and Theories} 		% (fold)
\label{sec:models} 

Philosophical approaches to scientific models have traditionally been connected to scientific theories. 
Early syntactic accounts, most prominently by logical empiricists, treated theories as axiomatic formal systems \citep[such as][]{carnap59,hempel66}
within which particular models can be articulated.
This view was criticised in part for not being an appropriate way to cast actual scientific theories. 
As a consequence, several approaches that focused on mathematical equations rather than logical propositions were developed.
They come in many variants, but generally agree that a theory is constituted by a set of related models. 
While some maintain the goal of axiomatically reconstructing theories \citep[among them][]{suppes60}, others do not, among them \citep{giere88}.
The semantic approach, as it became called, focuses on the content and representation of models rather than merely on their syntactic structure.
Here, the notion of isomorphism has played a strong role in relating the phenomena to the features of the models that describe them \citep{vf80}. 
A theory on this view could be a set of principles, core equations, or axioms from which models can be built, or it could be a set of non-hierarchically related models. These relations can be formal \citep{suppes60} or epistemic \citep{giere88}.
A purely syntactic view of theories will not allow one to develop a genuine conception of model independence in particle physics, because every QFT, including EFTs, and indeed every Lagrangian, is a model of the theory and thus the distinction in practice that we are hoping to capture would simply be defined away. 
In order to assess bottom-up strategies like SM-EFT, we have to look at those philosophical conceptions of models that emphasize their autonomy from the framework theory or even take them as primary and emphasize their epistemic role. 
After discussing the philosophical literature on models and theories relevant for our problem, we will present the bottom-up SM-EFT approach in more detail in Section~\ref{sec:classification} and review a case study in Section~\ref{sec:BphysicsConcepts} before applying this discussion to extract philosophical lessons in Section~\ref{sec:analysis}.

\subsection{Models and Theories}
\label{sub:modeltheory}

In moving from syntactic to semantic views, the focus of philosophical analysis shifted from theories to models and this also informed accounts that stressed the autonomy or independence of models from theories, such as the practice-based approaches of \citet{cartwright99}, and \citet{morganmorrison}.
By and large, accounts of models have become broader and more encompassing.
A model no longer needs to be an interpretation of a formal system, a set-theoretic entity, or an isomorphic representation, but can be determined by in part by its function and use in scientific practice.
The distinction between model and theory can be one of degree more than kind, where a theory has broader empirical scope and is more highly confirmed. 
In this Section, we will analyse the distinction in the context of two approaches that have already played a role in discussions of elementary particle physics, the practice-based account of \citet{morganmorrison} and the semantic account of \citet{hartmann1998}. 
While the MaM approach emphasizes the representative and autonomous roles of models in scientific practice, Hartmann's  hierarchy of theories and models attributes a stronger role to framework theories, such as QFT, thus being somewhat closer to Suppes' version of the semantic view \citep{suppes1962}. 


On the MaM view, ``the rough and ready distinction followed by scientists is usually to reserve the word model for an account of a process that is less certain or incomplete in important respects. 
Then as the model is able to account for more phenomena and has survived extensive testing it evolves into a theory'' \citep[p.~18]{morganmorrison}. 
\citeauthor{morganmorrison} identify four basic elements of models: 
\begin{enumerate}
	\item They are partially autonomous from both theory and data.
	\item They are purpose-built
	\item They are representative
	\item They enable us to learn about the world
\end{enumerate}
We take it to be fairly uncontroversial that models allow us to learn and that they are built with a variety of purposes in mind.
As such, we will focus our discussion on the remaining two elements.
We will first examine autonomy of models by reviewing the relations between models and theories and move to representation in Section~\ref{sub:reptarget}.
One can see that models are partially autonomous from data and theory from the way they are constructed and function.
Models are not derived entirely from theory or from data, but partly from both and their construction avails itself of scientific practices such as simplification, idealisation, and approximation.
A model is autonomous in that it can be an object of study or a tool in investigations of the world independently of its relation to the formal framework of a theory.

Let us now view the model-theory relation from the perspective of \citet{hartmann1998}, who distinguishes two kinds of theories and two kinds of models:
\begin{itemize}
\item A Type-A theory is a general background theory, quantum field theory in our case. We understand this theory to include a set of techniques like renormalization and only require that it is consistent in a physical sense. 
\item A Type-B theory is a fundamental ``model-theoretical model of a Type A theory, that is a concrete realization of the general formalism of QFT'' \citep[][p.~101]{hartmann1998}. This theory is called fundamental because ``{\it at the moment} everything that can be said about the respective domain of applicability can be captured" (ibid.) by it. 
Hartmann's examples are QED and QCD.
\end{itemize}
All other theoretical constructs are models. 


\begin{itemize}
\item Type-A models are non-fundamental model-theoretical models. They can be simple toy models for a Type-A theory or be as specific as variants or speculative modifications of a Type-B theory. 
Hartmann's example is a quartic interaction $\phi^4$ theory, but it seems to us that also most BSM models belong in this class as long as they do not fall outside the framework of QFT. 
The important point is that these models are models from a formal point of view. 

\item A Type-B model, or phenomenological model, is ``a set of assumptions about some object or system. Some of these assumptions may be \emph{inspired} by a Type-B theory, others may even contradict the relevant theory (in case there is any)'' (ibid.). Accordingly, Type-B models are rather a residual category in Hartmann's fourfold classification. 
They are not necessarily models in a syntactic or semantic sense, but emerge from scientific practice. 
Hartmann's examples are the various models of nuclear and hadronic structure that were developed long before QCD, models which later could be integrated into this formal framework. 
\end{itemize}

Hartmann's understanding of being `fundamental' involves a relationship between the theoretical constructs and the domain of facts known at the time in such a way that if a fundamental model describes a broader domain of facts, it becomes a theory in line with Morrison's above quoted terminology. However, Hartmann seems well aware that his understanding of fundamental is quite permissive. Discussing non-renormalizable EFTs as Type B models he concludes that, if one interprets the cut-off physically as their domain of applicability, ``at a given energy scale E a suitably chosen EFT can be fundamental in the sense that (practically) nothing more can be said about the ongoing physics" (p.~104).

Hartmann's examples for Type-B models also correspond to phenomenological models in the MaM approach as examples that ``make use of a variety of theoretical and empirical assumptions'' \citep[][p.~45]{morrison99}.
Their autonomy is based on certain representative features that are not fully derivable from theory or may even go beyond the available background theory, if any.  
Hartmann's requirements for Type-B models seem lower than those of MaM because he only requires `a set of assumptions', and not any partially autonomous representative features. 
Yet his partly hierarchical account emphasizes the role of the background theory and of Type-B theories more strongly, while MaM start from the models' autonomy and their epistemic function. 
In their approach, the existence of what Hartmann calls a Type-A theory is not required---as long there is some framework or some tangible way to study the model. 
Having a well developed framework theory is not excluded in MaM, but the autonomy of models kicks in because the framework theory is insufficient to make clear predictions or to derive the model in a canonical way. This is precisely the situation in particle physics.
\footnote{Note that a hierarchical approach, in the sense of Hartmann and Suppes, also stands behind Karaca's \citeyear{karaca2013} distinction between a framework theory, a model theory (the Type-B theories, in Hartmann's sense) and phemomenological models (Type-A or Type-B models, in Hartmann's sense).  \citet{karaca2018} also extends, but qualifies, a similar levelling into models of the detector etc.---which are not of concern here.}

Putting MaM alongside Hartmann's version of a semantic approach we find two, only partially overlapping uses of `model' that one can also discern in the broader philosophical literature. 
One where a model is defined as a restricted or specified part of a scientific theory that is related to a domain of phenomena, and one where a model is built in practice by studying real-world phenomena.
This also implies that the concepts of `theory' and `model' operate on different levels, in the sense that, on some accounts, model building begins within an existing theoretical framework while, on others, it proceeds initially without regard for such a theoretical framework, even though models may well become theories. While MaM clearly belongs into the latter category, Hartmann's account belongs to the former, apart from his introduction of the residual class of phenomenological models. 


\subsection{Representation and Target} \label{sub:reptarget}

Let us now turn to the fourth element of MaM, representation.
In contrast to the traditional view where a model must be isomorphic to, or somehow mirror, the phenomenon, representation for MaM is instead taken as ``a kind of rendering---a partial representation that either abstracts from, or translates into another form, the real nature of the system or theory, or one that is capable of embodying only a portion of a system'' \citep[p.~27]{morganmorrison}.
Models can be representative of either the world (their ``target system'') or of theory, they can also represent both, one more than the other. 
For instance, the hydrodynamic model of the boundary layer discussed by \citep{morrison99} demonstrates how representation can happen in both directions.
Prandtl built a small water tunnel that acted as a representation of the world, which exhibited different behaviours in different regions and allowed him to construct a mathematical model.
The mathematical model in turn represented aspects of both the classical theory and the Navier-Stokes equations, neither of which could be applied directly to the real world. 
Thus, the models represented in different ways, had different targets of representation, and acted as mediators between theories and the world. 
Morrison contrasts the boundary layer model, where one has to develop a target for mathematically efficient representation, to wit, the boundary layer, with the mathematical pendulum, where the formalism of Newtonian mechanics provides all the formal tools for a de-idealisation, i.e., possible terms for the introduction of friction, finite size of the bob, etc. 
It is this emphasis on the practical aspects of representation that distinguishes MaM from Hartmann's more theory-based approach---even though Hartmann's residual category (Type-B models) is pretty elastic.

In our use of representation, we follow MaM and make no strong demands on isomorphism or accurate representation and gladly accept the important role of modelling practices, such as idealisation, approximation, and abstraction. 
We take a representation to be a mathematical description of a potentially observable element of the world. 
In our specific context, these elements are of physics beyond the SM, such as new fields and vertices.
Because we take a model to be a model of something, then what it represents needs to be, in a sense, distinct and well defined. 
If it is a genuine model of BSM physics, then its target is some purported phenomenon beyond the SM and what it represents needs to be distinct from the SM. 
If a BSM model has a distinct and well-defined representational target it will allow physicists to make specific predictions about new physics.

While the MaM approach requires that a model has some target or even representative features, others have argued  
that representation is not a characteristic feature of a scientific model.
Some practice-based approaches consider representation an accomplishment of model-users rather than a feature of the model itself.
\citet{knuuttila2011,Knuuttila2017} and \citet{teller01} have argued that there is no general account of how and in virtue of what scientific models can be said to be adequate representations. 
In a sense, anything can stand for anything and what represents something is what is chosen to represent it.
This representation can be successful or not for a given end, but whether it represents or not is not decided by features of the model or the target.
On accounts such as Knuuttila's, the key features of models are epistemic: they are tools that allow us to learn, to make good inferences, to convey useful information about the world, and the role of representation is no longer central.
Knuuttila argues that representationalist views of modelling come up against problems because they treat models as distinct objects that need to be mapped to the world in order to justify their success. 
By contrast, she develops an artefactual account that attempts to dissolve these problems by conceiving of models as epistemic tools rather than abstract objects.

This ``amounts to regarding [models] as concrete artefacts that are built by specific representational means and are constrained by their design in such a way that they facilitate the study of certain scientific questions, and learning from them by means of construction and manipulation'' \citep[p.~262]{knuuttila2011}.
She lists five characteristics of models as epistemic tools:
``(i) the constrained design of models, (ii) non-transparency of the representational means by which they are constructed, (iii) their results-orientedness, (iv) their concrete manipulability and (v) the way their justification is distributed so as to cover both the construction and the use of models'' \citep[p.~267]{knuuttila2011}.
The epistemic characteristic of models does not include accurate representation, but neither is it precluded.
Representation is always an accomplishment. 
But a model's success cannot be assessed without ``the culturally established external representational tools that enable, embody and extend scientific imagination and reasoning'' \citep[p.~1]{Knuuttila2017}. 
They ``form an ineliminable part of the model itself,'' (p. 3) not just of its description. 
``What distinguishes models from many other kinds of representations is often their systemic, autonomous nature,'' (p. 17) which they share with fictions.
Knuuttila illustrates her artefactual account with the example of highly-idealised mathematical models that are applicable in unrelated empirical contexts. 


\subsection{Effective Field Theories}

There already exists considerable philosophical literature on effective field theory.
Philosophical attention turned to EFTs in the late 1980s and early 1990s with the seminal papers by \citet{teller89}, \citet{cao1993}, and \citet{huggetweingard}. 
From these discussions various metaphysical and ontological arguments were picked up in \citet{castellani2002} and \citet{fraser2009}, and more recently in \citep{bain2013a,Ruetsche2018,williams2018}. 
A substantial part of these debates focuses on whether EFTs can be interpreted in realist terms, or whether they are robust or fundamental enough to be worthy of philosophers' attention as compared to axiomatized approaches---which, to Williams' mind---still are in the focus of philosophical orthodoxy. 
Williams' `effective realism' about EFT is certainly one way to justify the value of EFTs. 
But we have to note that he and most of the other authors have focused on top-down EFTs whereas our focus is on the bottom-up approach of the SM-EFT.
One exception is \citet{wells2011} who examines bottom-up EFTs as a general method, or mind-frame, for scientific research that could have been used, he argues, to point the way towards general relativity by predictions about the perihelion precession of Mercury already in the late 19th century. 
The in-principle feasibility of such a bottom-up approach, to his mind, suggests that physicists focus on improving theories through EFTs and not be exclusively concerned with principles and justifications.
Wells does not discuss whether this makes EFTs similar to models.

We take our discussion to pick up on questions introduced by \citet{hartmann2001}, who takes a detailed look at the history and development of EFTs in the context of models and theories. 
In looking at case studies in hadron physics, he argues that EFTs produce scientific understanding of the processes they are modelling; they are simple, intuitive, and satisfy a variety of pragmatic and cognitive goals. 
For Hartmann, unlike for \citet{cao1993}, EFTs do not indicate an anti-foundationalist metaphysics, nor will they eclipse models or theories. There is rather an interplay between theories, models, and EFTs in physics research and distinguishing them is not always easy. 
``EFTs share many of the functions of theories and models. Like models, they provide a local, intuitive account of a given phenomenon in terms of the degrees of freedom which are relevant at the energy scale under consideration. They are relatively easy to solve and to apply, and they are heuristically useful\ldots Like theories, EFTs are part of a bigger picture or framework, from which they can be derived in a controlled way. They help to make predictions and to test the theory they relate to'' (2001, p.~294). 
Among Hartmann's examples are the above-discussed Fermi theory and the V--A theory of the weak interaction. 
% Though Hartmann primarily focuses on top-down EFTs, 
Our analysis similarly finds that the SM-EFT has complex relations to theories and models. 
While accordingly this double relationship remains, there are significant differences and we will argue that its nature may even depend on the experimental success of the SM-EFT.


